{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'y1function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f5997eb26c89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnew_var\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC3function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC6function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moutliers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moutlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'y1function'"
     ]
    }
   ],
   "source": [
    "# Importing useful packages\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from new_var import calc,y1function,y2function,C3function,C6function\n",
    "from outliers import outlier\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "ipo_data = pd.read_excel(\"Competition #1 Raw Data_UPDATED I3.xlsx\",header=0,na_values='-' )\n",
    "# Replacing NaN values with their corresponding mean value\n",
    "\n",
    "ipo_data=ipo_data.fillna(ipo_data.mean())\n",
    "\n",
    "\n",
    "# Removing 0 and negatives for T' calculations        \n",
    "ipo_data['T2']=ipo_data['T2'].mask(ipo_data['T2'] <= 0,ipo_data['T2'].mean())\n",
    "ipo_data['T1']=ipo_data['T1'].mask(ipo_data['T1'] <= 0,ipo_data['T1'].mean())\n",
    "ipo_data['T3']=ipo_data['T3'].mask(ipo_data['T3'] <= 0,ipo_data['T3'].mean())\n",
    "ipo_data['T4']=ipo_data['T4'].mask(ipo_data['T4'] <= 0,ipo_data['T4'].mean())\n",
    "ipo_data['T5']=ipo_data['T5'].mask(ipo_data['T5'] <= 0,ipo_data['T5'].mean())\n",
    "ipo_data['S1']=ipo_data['S1'].mask(ipo_data['S1'] <= 0,ipo_data['S1'].mean())\n",
    "ipo_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data['Y1'] = ipo_data.apply(y1function, axis=1)\n",
    "ipo_data['Y2'] = ipo_data.apply(y2function, axis=1)\n",
    "ipo_data['C3x'] = ipo_data.apply(C3function, axis=1)\n",
    "ipo_data['C6x'] = ipo_data.apply(C6function, axis=1)\n",
    "calc(ipo_data)\n",
    "del ipo_data['C3']\n",
    "del ipo_data['C5']\n",
    "del ipo_data['C6']\n",
    "del ipo_data['T1']\n",
    "del ipo_data['T2']\n",
    "del ipo_data['T3']\n",
    "del ipo_data['T4']\n",
    "del ipo_data['T5']\n",
    "del ipo_data['S1']\n",
    "del ipo_data['S2']\n",
    "del ipo_data['S3']\n",
    "ipo_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing variables to correct type\n",
    "ipo_data.C6x = ipo_data.C6x.astype(float)\n",
    "\n",
    "ipo_data.C2 = ipo_data.C2.astype(int)\n",
    "print(ipo_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqrt_transform=['C6x','T3x','T5x','S1x','S2x','S3x'] #Variables that need to be square rooted\n",
    "ipo_data[sqrt_transform]=ipo_data[sqrt_transform]**0.5 #square rooting variable\n",
    "\n",
    "log_transform=['C1','C7'] #Variables to be log transformed\n",
    "ipo_data[log_transform]=np.log(ipo_data[log_transform])#log transformation\n",
    "\n",
    "\n",
    "def standard(data,method):\n",
    "    if method == 1:\n",
    "        X_std = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
    "        data = X_std * (1 - 0) + 0\n",
    "        return data\n",
    "    elif method==2:\n",
    "        data = (data)/(10**len(str(int(max(data))))) \n",
    "train=['C3x','C4','C1','C7','C6x','T3x','T4x','T5x','S1x','S2x','S3x','C2']\n",
    "#normal_col=['C4','C1','C7','C6x','T3x','T4x','T5x','S1x','S2x','S3x']\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through our functions and building models for each combination in order to view best results\n",
    "for j in range(1,5):\n",
    "    # Creating data set for the model\n",
    "    x=pd.DataFrame.copy(ipo_data)\n",
    "    for i in range(len(x.columns)): \n",
    "        if x.iloc[:,i].dtype == float:\n",
    "            outlier(x.iloc[:,i],j)\n",
    "            for l in range(1,2):\n",
    "                if x.iloc[:,i].dtype == float:   \n",
    "                    x.iloc[:,i]=standard(x.iloc[:,i],1)\n",
    "    print('Outlier Method {}; Standardise Method {}'.format(j,l))\n",
    "    \n",
    "    # Model creation starts here\n",
    "    logreg = LogisticRegression()\n",
    "    \n",
    "    train=['C3x','C4','C1','C7','T3x','T4x','T5x','S1x','S2x','S3x','C2']\n",
    "    X=x[train]\n",
    "    y=x['Y1']\n",
    "    rfe = RFE(logreg, 18)\n",
    "    rfe = rfe.fit(X,y)\n",
    "\n",
    "    logit_model=sm.Logit(x['Y1'],x[train])\n",
    "    result=logit_model.fit()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    modelCV = LogisticRegression()\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    #confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(rfe.support_)\n",
    "    print(rfe.ranking_)\n",
    "    print(result.summary())\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "\n",
    "    print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing our sample due to in balance between y2=1 and y2=0\n",
    "df_subset = ipo_data.loc[ipo_data['Y2'] == 1].sample(300)\n",
    "ipo_data = ipo_data.drop(df_subset.index)\n",
    "\n",
    "\n",
    "\n",
    "for j in range(1,5):\n",
    "    x=pd.DataFrame.copy(ipo_data)\n",
    "    for i in range(len(x.columns)): \n",
    "        if x.iloc[:,i].dtype == float:\n",
    "            outlier(x.iloc[:,i],j)             \n",
    "            if x.iloc[:,i].dtype == float:   \n",
    "                x.iloc[:,i]=standard(x.iloc[:,i],1)\n",
    "    print('Outlier Method {}; Standardise Method {}'.format(j,1))\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    #train=['C4','C6x','T4x','S2x']\n",
    "    #train=['C3x','C4','T3x','T4x','S1x','S2x','C2']\n",
    "    train=['C3x','C4','C1','C7','C6x','T3x','T4x','T5x','S1x','S2x','S3x','C2']\n",
    "    X=x[train]\n",
    "    y=x['Y2']\n",
    "    rfe = RFE(logreg, 18)\n",
    "    rfe = rfe.fit(X,y)\n",
    "\n",
    "    logit_model=sm.Logit(x['Y2'],x[train])\n",
    "    result=logit_model.fit()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    modelCV = LogisticRegression()\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    #confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(rfe.support_)\n",
    "    print(rfe.ranking_)\n",
    "    print(result.summary())\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "\n",
    "    print(confusion_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
